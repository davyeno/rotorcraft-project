{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8708b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\School\\Graduate 2022 Summer\\Data\\OneDrive_1_7-3-2022\n"
     ]
    }
   ],
   "source": [
    "%cd \"D:\\School\\Graduate 2022 Summer\\Data\\OneDrive_1_7-3-2022\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbee1579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\School\\\\Graduate 2022 Summer\\\\Data\\\\OneDrive_1_7-3-2022'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50445aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fe988fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_file = pd.read_csv('SimData_2022.06.30_10.27.04.csv.roar.csv',\n",
    "                parse_dates = {'datetime': ['date', 'time']},\n",
    "                low_memory=False)\n",
    "\n",
    "second_file = pd.read_csv('SimData_2022.06.30_13.01.46.csv.roar.csv',\n",
    "                parse_dates = {'datetime': ['date', 'time']},\n",
    "                low_memory=False)\n",
    "\n",
    "third_file = pd.read_csv('SimData_2022.06.30_13.05.32.csv.roar.csv',\n",
    "                parse_dates = {'datetime': ['date', 'time']},\n",
    "                low_memory=False)\n",
    "\n",
    "fourth_file = pd.read_csv('SimData_2022.06.30_13.42.04.csv.roar.csv',\n",
    "                parse_dates = {'datetime': ['date', 'time']},\n",
    "                low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f658e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 2] The system cannot find the file specified: 'D:\\\\School\\\\Graduate 2022 Summer\\\\Data\\\\OneDrive_1_7-10-2022'\n",
      "D:\\School\\Graduate 2022 Summer\\Data\\OneDrive_1_7-3-2022\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'SimData_2022.07.07_09.56.57.csv.roar.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcd\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mSchool\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mGraduate 2022 Summer\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mData\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mOneDrive_1_7-10-2022\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m fifth_file \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSimData_2022.07.07_09.56.57.csv.roar.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdatetime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                \u001b[49m\u001b[43mlow_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# adding this file to balance hover or not\u001b[39;00m\n\u001b[0;32m      8\u001b[0m sixth_file \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSimData_2022.07.07_14.32.46.csv.roar.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      9\u001b[0m                 parse_dates \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m]},\n\u001b[0;32m     10\u001b[0m                 low_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'SimData_2022.07.07_09.56.57.csv.roar.csv'"
     ]
    }
   ],
   "source": [
    "%cd \"D:\\School\\Graduate 2022 Summer\\Data\\OneDrive_1_7-10-2022\"\n",
    "\n",
    "fifth_file = pd.read_csv('SimData_2022.07.07_09.56.57.csv.roar.csv',\n",
    "                parse_dates = {'datetime': ['date', 'time']},\n",
    "                low_memory=False)\n",
    "\n",
    "# adding this file to balance hover or not\n",
    "sixth_file = pd.read_csv('SimData_2022.07.07_14.32.46.csv.roar.csv',\n",
    "                parse_dates = {'datetime': ['date', 'time']},\n",
    "                low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a989436a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([first_file, second_file, third_file, fourth_file, fifth_file, sixth_file])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1f4dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[['datetime',\n",
    "          'latitude',\n",
    "          'longitude',\n",
    "          'absoluteAltitude', \n",
    "          'magneticHeading',\n",
    "          'trueHeading', \n",
    "          'groundSpeed', \n",
    "          'trueAirspeed',\n",
    "          'pitch', \n",
    "          'roll',\n",
    "          'yaw',\n",
    "          'angleOfAttack',\n",
    "          'flightPathAngle',\n",
    "          'verticalFlightPathAngle',\n",
    "          'horizontalFlightPathAngle',\n",
    "          'rollAcceleration',\n",
    "          'pitchAcceleration',\n",
    "          'yawAcceleration',\n",
    "          'e1N1ng',\n",
    "          'e2N1ng',\n",
    "          'e1N2nf',\n",
    "          'e2N2nf',\n",
    "          'mainRotorRpm',\n",
    "          'tailRotorRpm',\n",
    "          'mainRotorTorque',\n",
    "          'e1Itt',\n",
    "          'e2Itt',\n",
    "          'mainRotorInducedInflow',\n",
    "          'flightDirectorPitch',\n",
    "          'flightDirectorRoll',\n",
    "          'climbOrDescentRate', \n",
    "          'hasWeightOnWheels',\n",
    "          'turnRate to degPerSec',\n",
    "          'cyclicPositionPitch',\n",
    "          'cyclicPositionRoll',\n",
    "          'collectivePosition',\n",
    "          'antiTorquePedalPosition',\n",
    "          'throttlePosition',\n",
    "          'e1Torque',\n",
    "          'e2Torque',\n",
    "]] # only capture columns that relevant into another dataframe\n",
    "\n",
    "# Convert timestamp into year month day and hour in seconds \n",
    "# eliminate the milliseonds part in order to group them by seconds with an average\n",
    "df2['datetime'] = df2.datetime.dt.strftime('%Y-%m-%d %H:%M:%S').astype('datetime64[ns]')\n",
    "\n",
    "\n",
    "# Group all row by seconds with a average all the datapoint into another dataframe\n",
    "df3 = df2.groupby(by=[\"datetime\"], dropna=False).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf412f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ######### For deep learning model\n",
    "# df3 = df[['datetime',\n",
    "#           'latitude',\n",
    "#           'longitude', \n",
    "#           'absoluteAltitude', \n",
    "#           'trueHeading', \n",
    "#           'groundSpeed', \n",
    "#           'trueAirspeed', \n",
    "#           'climbOrDescentRate', \n",
    "#           'hasWeightOnWheels', \n",
    "#           'turnRate to degPerSec', \n",
    "#           'cyclicPositionPitch', \n",
    "#           'cyclicPositionRoll', \n",
    "#           'collectivePosition', \n",
    "#           'antiTorquePedalPosition', \n",
    "#           'throttlePosition', \n",
    "#           'e1Torque', \n",
    "#           'e2Torque',\n",
    "# ]] # only capture columns that relevant into another dataframe\n",
    "\n",
    "# # Convert timestamp into year month day and hour in seconds \n",
    "# # eliminate the milliseonds part in order to group them by seconds with an average\n",
    "# # df2['datetime'] = df2.datetime.dt.strftime('%Y-%m-%d %H:%M:%S').astype('datetime64[ns]')\n",
    "\n",
    "\n",
    "# # Group all row by seconds with a average all the datapoint into another dataframe\n",
    "# # df3 = df2.groupby(by=[\"datetime\"], dropna=False).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42841612",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['HoverOrNot'] = 0\n",
    "\n",
    "df3.loc[(df3['datetime'].between('2022-06-30 14:28:13' , '2022-06-30 14:33:12' , inclusive='both')),['HoverOrNot']] = 1\n",
    "\n",
    "df3.loc[(df3['datetime'].between('2022-06-30 14:34:10' , '2022-06-30 14:38:29' , inclusive='both')),['HoverOrNot']] = 1\n",
    "\n",
    "df3.loc[(df3['datetime'].between('2022-06-30 14:40:10' , '2022-06-30 14:43:40' , inclusive='both')),['HoverOrNot']] = 1\n",
    "\n",
    "df3.loc[(df3['datetime'].between('2022-06-30 14:46:00' , '2022-06-30 14:55:55' , inclusive='both')),['HoverOrNot']] = 1\n",
    "\n",
    "df3.loc[(df3['datetime'].between('2022-06-30 14:57:10' , '2022-06-30 15:00:16' , inclusive='both')),['HoverOrNot']] = 1\n",
    "\n",
    "df3.loc[(df3['datetime'].between('2022-06-30 15:01:20' , '2022-06-30 15:07:03' , inclusive='both')),['HoverOrNot']] = 1\n",
    "\n",
    "df3.loc[(df3['datetime'].between('2022-06-30 15:07:38' , '2022-06-30 15:10:38' , inclusive='both')),['HoverOrNot']] = 1\n",
    "\n",
    "df3.loc[(df3['datetime'].between('2022-06-30 15:12:02' , '2022-06-30 15:18:30' , inclusive='both')),['HoverOrNot']] = 1\n",
    "\n",
    "df3.loc[(df3['datetime'].between('2022-06-30 15:20:18' , '2022-06-30 15:23:52' , inclusive='both')),['HoverOrNot']] = 1\n",
    "\n",
    "df3.loc[(df3['datetime'].between('2022-06-30 15:25:30' , '2022-06-30 15:30:17' , inclusive='both')),['HoverOrNot']] = 1\n",
    "\n",
    "df3.loc[(df3['datetime'].between('2022-06-30 15:36:45' , '2022-06-30 15:40:24' , inclusive='both')),['HoverOrNot']] = 1\n",
    "\n",
    "df3.loc[(df3['datetime'].between('2022-06-30 15:42:28' , '2022-06-30 15:55:20' , inclusive='both')),['HoverOrNot']] = 1\n",
    "\n",
    "\n",
    "# Combine with the new data\n",
    "\n",
    "df3.loc[(df3['datetime'].between('2022-07-07 13:58:38' , '2022-07-07 14:02:54' , inclusive='both')),['HoverOrNot']] = 1\n",
    "\n",
    "df3.loc[(df3['datetime'].between('2022-07-07 14:03:40' , '2022-07-07 14:11:19' , inclusive='both')),['HoverOrNot']] = 1\n",
    "\n",
    "df3.loc[(df3['datetime'].between('2022-07-07 14:14:55' , '2022-07-07 14:21:03' , inclusive='both')),['HoverOrNot']] = 1\n",
    "\n",
    "df3.loc[(df3['datetime'].between('2022-07-07 14:22:19' , '2022-07-07 14:23:18' , inclusive='both')),['HoverOrNot']] = 1\n",
    "\n",
    "df3.loc[(df3['datetime'].between('2022-07-07 14:24:20' , '2022-07-07 14:35:00' , inclusive='both')),['HoverOrNot']] = 1\n",
    "\n",
    "df3.loc[(df3['datetime'].between('2022-07-07 14:36:00' , '2022-07-07 14:45:24' , inclusive='both')),['HoverOrNot']] = 1\n",
    "\n",
    "df3.loc[(df3['datetime'].between('2022-07-07 14:46:50' , '2022-07-07 14:47:20' , inclusive='both')),['HoverOrNot']] = 1\n",
    "\n",
    "\n",
    "# Double check to see hasWeightOnWheels = 1, then set Hover Or Not = 0\n",
    "df3.loc[(df3['hasWeightOnWheels'] == 1), ['HoverOrNot']] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b7f2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(df3[(df3['HoverOrNot'] == 1)]) #6310\n",
    "len(df3[(df3['HoverOrNot'] == 0)]) #6645"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1cc76e",
   "metadata": {},
   "source": [
    "<h2> Since hover data is only 1/4 of the dataset, hence we have to randomly select the same amount of data for not hover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8e3dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly sample dataset where hoverOrNot is 0\n",
    "df4 = df3[(df3['HoverOrNot'] == 0)].sample(n=6310, replace=False, random_state=123458)\n",
    "\n",
    "# Concat data from where HoverOrNot = 1 and HoverOrNot = 0\n",
    "\n",
    "df5 = pd.concat([df3[(df3['HoverOrNot'] == 1)], df4], ignore_index=True)\n",
    "\n",
    "# Shuffle data in random way\n",
    "df5 = df5.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183e0aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "from matplotlib import cm\n",
    "\n",
    "feature_names = ['absoluteAltitude',\n",
    "                 'magneticHeading', \n",
    "                 'groundSpeed', \n",
    "                 'climbOrDescentRate',\n",
    "                 'turnRate to degPerSec',\n",
    "                 'cyclicPositionPitch',\n",
    "                 'cyclicPositionRoll',\n",
    "                 'collectivePosition',\n",
    "                 'antiTorquePedalPosition',\n",
    "                 'throttlePosition',\n",
    "                 'e1Torque',\n",
    "                 'e2Torque']               \n",
    "                \n",
    "                \n",
    "X = df5[feature_names]\n",
    "y = df5['HoverOrNot']\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=516516)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee7b44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
    "              'kernel': ['rbf']}\n",
    " \n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose=3)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a23150",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8dbc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba1d36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "print('Accuracy of SVM classifier on training set: {:.2f}'\n",
    "     .format(svm.score(X_train, y_train)))\n",
    "print('Accuracy of SVM classifier on test set: {:.2f}'\n",
    "     .format(svm.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d249128f",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09ae267",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'D:/git/rotorcraft-project/david/svm_trained_model.sav'\n",
    "pickle.dump(svm, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885260b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "xgb_cl  = xgb.XGBClassifier(\n",
    "                objective=\"binary:logistic\",\n",
    "                )\n",
    "param_grid = {\n",
    "    'max_depth': [3, 4, 5, 7],\n",
    "    'learning_rate': [0.1, 0.01, 0.05],\n",
    "    'gamma': [0, 0.25, 1],\n",
    "    'reg_lambda': [0, 1, 10],\n",
    "    'scale_pos_weight': [1, 3, 5],\n",
    "    'subsample': [0.8],\n",
    "    'colsample_bytree': [0.5],\n",
    "}\n",
    "grid_cv = GridSearchCV(xgb_cl, param_grid, n_jobs=-1, cv=3, scoring=\"roc_auc\")\n",
    "_ = grid_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b8cf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960593a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82977d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_classifier = xgb.XGBClassifier(\n",
    "    **grid_cv.best_params_,\n",
    "    objective=\"binary:logistic\",\n",
    ")\n",
    "\n",
    "xgb_classifier.fit(X_train,y_train)\n",
    "\n",
    "print('Accuracy of XGBoost Classifier on training set: {:.2f}'\n",
    "     .format(accuracy_score(y_train, xgb_classifier.predict(X_train))))\n",
    "\n",
    "\n",
    "print('Accuracy of XGBoost classifier on test set: {:.2f}'\n",
    "     .format(accuracy_score(y_test, xgb_classifier.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347b743b",
   "metadata": {},
   "source": [
    "<h2> Using XGBoost model to predict the validation file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb1441f",
   "metadata": {},
   "source": [
    "<H4> Processing the validation file to make it into the same structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdfe487",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd \"D:\\School\\Graduate 2022 Summer\\Data\\OneDrive_1_7-3-2022\"\n",
    "\n",
    "# valid_data1 = pd.read_csv('SimData_2022.06.30_09.16.15.csv.roar.csv',\n",
    "#                 parse_dates = {'datetime': ['date', 'time']},\n",
    "#                 low_memory=False)\n",
    "\n",
    "validation_file = pd.read_csv('SimData_2022.06.30_09.43.28.csv.roar.csv',\n",
    "                parse_dates = {'datetime': ['date', 'time']},\n",
    "                low_memory=False)\n",
    "\n",
    "# validation_file = pd.concat([valid_data2], ignore_index=True)\n",
    "\n",
    "validation_file = validation_file[['datetime',\n",
    "          'latitude',\n",
    "          'longitude',\n",
    "          'absoluteAltitude',\n",
    "          'magneticHeading',\n",
    "          'trueHeading', \n",
    "          'groundSpeed', \n",
    "          'trueAirspeed',\n",
    "          'pitch', \n",
    "          'roll',\n",
    "          'yaw',\n",
    "          'angleOfAttack',\n",
    "          'flightPathAngle',\n",
    "          'verticalFlightPathAngle',\n",
    "          'horizontalFlightPathAngle',\n",
    "          'rollAcceleration',\n",
    "          'pitchAcceleration',\n",
    "          'yawAcceleration',\n",
    "          'e1N1ng',\n",
    "          'e2N1ng',\n",
    "          'e1N2nf',\n",
    "          'e2N2nf',\n",
    "          'mainRotorRpm',\n",
    "          'tailRotorRpm',\n",
    "          'mainRotorTorque',\n",
    "          'e1Itt',\n",
    "          'e2Itt',\n",
    "          'mainRotorInducedInflow',\n",
    "          'flightDirectorPitch',\n",
    "          'flightDirectorRoll',\n",
    "          'climbOrDescentRate', \n",
    "          'hasWeightOnWheels',\n",
    "          'turnRate to degPerSec',\n",
    "          'cyclicPositionPitch',\n",
    "          'cyclicPositionRoll',\n",
    "          'collectivePosition',\n",
    "          'antiTorquePedalPosition',\n",
    "          'throttlePosition',\n",
    "          'e1Torque',\n",
    "          'e2Torque',\n",
    "]] # only capture columns that relevant into another dataframe\n",
    "\n",
    "# Convert timestamp into year month day and hour in seconds \n",
    "# eliminate the milliseonds part in order to group them by seconds with an average\n",
    "validation_file['datetime'] = validation_file.datetime.dt.strftime('%Y-%m-%d %H:%M:%S').astype('datetime64[ns]')\n",
    "\n",
    "\n",
    "# Group all row by seconds with a average all the datapoint into another dataframe\n",
    "validation_file = validation_file.groupby(by=[\"datetime\"], dropna=False).mean().reset_index()\n",
    "\n",
    "validation_file['HoverOrNot'] = 0\n",
    "\n",
    "validation_file.loc[(validation_file['datetime'].between('2022-06-30 13:48:11' , '2022-06-30 13:52:20' , inclusive='both')),['HoverOrNot']] = 1\n",
    "\n",
    "validation_file.loc[(validation_file['datetime'].between('2022-06-30 13:53:15' , '2022-06-30 13:54:18' , inclusive='both')),['HoverOrNot']] = 1\n",
    "\n",
    "validation_file.loc[(validation_file['datetime'].between('2022-06-30 13:55:29' , '2022-06-30 13:56:15' , inclusive='both')),['HoverOrNot']] = 1\n",
    "validation_file.loc[(validation_file['datetime'].between('2022-06-30 13:56:23' , '2022-06-30 13:57:13' , inclusive='both')),['HoverOrNot']] = 1\n",
    "\n",
    "validation_file.loc[(validation_file['datetime'].between('2022-06-30 13:59:00' , '2022-06-30 14:00:14' , inclusive='both')),['HoverOrNot']] = 1\n",
    "\n",
    "validation_file.loc[(validation_file['datetime'].between('2022-06-30 14:02:12' , '2022-06-30 14:03:50' , inclusive='both')),['HoverOrNot']] = 1\n",
    "\n",
    "validation_file.loc[(validation_file['datetime'].between('2022-06-30 14:05:25' , '2022-06-30 14:16:45' , inclusive='both')),['HoverOrNot']] = 1\n",
    "\n",
    "validation_file.loc[(validation_file['datetime'].between('2022-06-30 14:18:10' , '2022-06-30 14:19:34' , inclusive='both')),['HoverOrNot']] = 1\n",
    "\n",
    "validation_file.loc[(validation_file['datetime'].between('2022-06-30 14:22:40' , '2022-06-30 14:24:40' , inclusive='both')),['HoverOrNot']] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec693ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validation = validation_file[feature_names]\n",
    "y_validation = validation_file['HoverOrNot']\n",
    "\n",
    "\n",
    "X_valid = scaler.transform(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ec6e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_xgb = xgb_classifier.predict(X_valid)\n",
    "print(\"Accuracy of Model::\",accuracy_score(y_validation,validation_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d9d986",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_svm = svm.predict(X_valid)\n",
    "print(\"Accuracy of Model::\",accuracy_score(y_validation,validation_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da51b09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_file['HoverOrNot'] = validation_file['HoverOrNot'] * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8442f6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "\n",
    "validation_file['xgb_predicted'] = validation_xgb * 20\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "# plt.plot('datetime','absoluteAltitude',\n",
    "#          data = validation_file,\n",
    "#          label = \"absoluteAltitude\")\n",
    "plt.plot('datetime','groundSpeed',\n",
    "         data = validation_file,\n",
    "         label = \"groundSpeed\")\n",
    "plt.plot('datetime','xgb_predicted',\n",
    "         data = validation_file,\n",
    "         label = \"xgb_predicted\")\n",
    "plt.plot('datetime','HoverOrNot',\n",
    "         data = validation_file,\n",
    "         label = \"HoverOrNot\")\n",
    "\n",
    "#Set format of the plot chart\n",
    "plt.gca().xaxis.set_major_locator(mdates.SecondLocator(interval=90))\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
    "plt.xticks(rotation=90)\n",
    "# plt.gcf().autofmt_xdate()\n",
    "\n",
    "\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Value') \n",
    "plt.title('XGBoost Model Prediction')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1297b86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "\n",
    "validation_file['svm_predicted'] = validation_svm * 20\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "# plt.plot('datetime','absoluteAltitude',\n",
    "#          data = validation_file,\n",
    "#          label = \"absoluteAltitude\")\n",
    "plt.plot('datetime','groundSpeed',\n",
    "         data = validation_file,\n",
    "         label = \"groundSpeed\")\n",
    "plt.plot('datetime','svm_predicted',\n",
    "         data = validation_file,\n",
    "         label = \"svm_predicted\")\n",
    "plt.plot('datetime','HoverOrNot',\n",
    "         data = validation_file,\n",
    "         label = \"HoverOrNot\")\n",
    "\n",
    "#Set format of the plot chart\n",
    "plt.gca().xaxis.set_major_locator(mdates.SecondLocator(interval=90))\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
    "plt.xticks(rotation=90)\n",
    "# plt.gcf().autofmt_xdate()\n",
    "\n",
    "\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Value') \n",
    "plt.title('SVM Model Prediction')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186596a7",
   "metadata": {},
   "source": [
    "<h2> Test again 7/10 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e780a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd \"D:\\School\\Graduate 2022 Summer\\Data\\OneDrive_1_7-10-2022\"\n",
    "\n",
    "valid_data_710 = pd.read_csv('SimData_2022.07.07_09.29.40.csv.roar.csv',\n",
    "                parse_dates = {'datetime': ['date', 'time']},\n",
    "                low_memory=False)\n",
    "\n",
    "# valid_data_710_2 = pd.read_csv('SimData_2022.07.07_09.56.57.csv.roar.csv',\n",
    "#                 parse_dates = {'datetime': ['date', 'time']},\n",
    "#                 low_memory=False)\n",
    "\n",
    "# valid_data_623_3 = pd.read_csv('SimData_2022.06.23_11.22.59.csv.roar.csv',\n",
    "#                 parse_dates = {'datetime': ['date', 'time']},\n",
    "#                 low_memory=False)\n",
    "\n",
    "# validation_file = pd.concat([valid_data_623_1,\n",
    "#                              valid_data_623_2,\n",
    "# #                              valid_data_623_3\n",
    "#                             ], ignore_index=True)\n",
    "\n",
    "validation_file = valid_data_710[['datetime',\n",
    "          'latitude',\n",
    "          'longitude',\n",
    "          'absoluteAltitude', \n",
    "          'magneticHeading',\n",
    "          'trueHeading', \n",
    "          'groundSpeed', \n",
    "          'trueAirspeed',\n",
    "          'pitch', \n",
    "          'roll',\n",
    "          'yaw',\n",
    "          'angleOfAttack',\n",
    "          'flightPathAngle',\n",
    "          'verticalFlightPathAngle',\n",
    "          'horizontalFlightPathAngle',\n",
    "          'rollAcceleration',\n",
    "          'pitchAcceleration',\n",
    "          'yawAcceleration',\n",
    "          'e1N1ng',\n",
    "          'e2N1ng',\n",
    "          'e1N2nf',\n",
    "          'e2N2nf',\n",
    "          'mainRotorRpm',\n",
    "          'tailRotorRpm',\n",
    "          'mainRotorTorque',\n",
    "          'e1Itt',\n",
    "          'e2Itt',\n",
    "          'mainRotorInducedInflow',\n",
    "          'flightDirectorPitch',\n",
    "          'flightDirectorRoll',\n",
    "          'climbOrDescentRate', \n",
    "          'hasWeightOnWheels',\n",
    "          'turnRate to degPerSec',\n",
    "          'cyclicPositionPitch',\n",
    "          'cyclicPositionRoll',\n",
    "          'collectivePosition',\n",
    "          'antiTorquePedalPosition',\n",
    "          'throttlePosition',\n",
    "          'e1Torque',\n",
    "          'e2Torque',\n",
    "]] # only capture columns that relevant into another dataframe\n",
    "\n",
    "# Convert timestamp into year month day and hour in seconds \n",
    "# eliminate the milliseonds part in order to group them by seconds with an average\n",
    "validation_file['datetime'] = validation_file.datetime.dt.strftime('%Y-%m-%d %H:%M:%S').astype('datetime64[ns]')\n",
    "\n",
    "\n",
    "# Group all row by seconds with a average all the datapoint into another dataframe\n",
    "validation_file = validation_file.groupby(by=[\"datetime\"], dropna=False).mean().reset_index()\n",
    "\n",
    "validation_file['HoverOrNot'] = 0\n",
    "\n",
    "validation_file.loc[(validation_file['datetime'].between('2022-07-07 13:30:49' , '2022-07-07 13:34:28' , inclusive='both')),['HoverOrNot']] = 1\n",
    "\n",
    "validation_file.loc[(validation_file['datetime'].between('2022-07-07 13:36:10' , '2022-07-07 13:38:05' , inclusive='both')),['HoverOrNot']] = 1\n",
    "\n",
    "validation_file.loc[(validation_file['datetime'].between('2022-07-07 13:40:44' , '2022-07-07 13:42:14' , inclusive='both')),['HoverOrNot']] = 1\n",
    "\n",
    "validation_file.loc[(validation_file['datetime'].between('2022-07-07 13:43:40' , '2022-07-07 13:45:07' , inclusive='both')),['HoverOrNot']] = 1\n",
    "\n",
    "validation_file.loc[(validation_file['datetime'].between('2022-07-07 13:47:03' , '2022-07-07 13:52:09' , inclusive='both')),['HoverOrNot']] = 1\n",
    "\n",
    "validation_file.loc[(validation_file['datetime'].between('2022-07-07 13:53:12' , '2022-07-07 13:53:55' , inclusive='both')),['HoverOrNot']] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468c8c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validation = validation_file[feature_names]\n",
    "y_validation = validation_file['HoverOrNot']\n",
    "\n",
    "\n",
    "X_valid = scaler.transform(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e5854a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_loaded = 'D:/git/rotorcraft-project/david/svm_trained_model.sav'\n",
    "svm_loaded = pickle.load(open(file_loaded, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a684f4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_svm = svm_loaded.predict(X_valid)\n",
    "print(\"Accuracy of Model::\",accuracy_score(y_validation,validation_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a07cc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_file['HoverOrNot'] = validation_file['HoverOrNot'] * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eea4945",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "\n",
    "validation_file['svm_predicted'] = validation_svm * 20\n",
    "# validation_file.loc[(validation_file['hasWeightOnWheels'] == 1),['svm_predicted']] = 0\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "plt.plot('datetime','groundSpeed',\n",
    "         data = validation_file,\n",
    "         label = \"groundSpeed\")\n",
    "plt.plot('datetime','svm_predicted',\n",
    "         data = validation_file,\n",
    "         label = \"svm_predicted\", color=\"orange\")\n",
    "plt.plot('datetime','HoverOrNot',\n",
    "         data = validation_file,\n",
    "         label = \"HoverOrNot\", color=\"r\")\n",
    "\n",
    "#Set format of the plot chart\n",
    "plt.gca().xaxis.set_major_locator(mdates.SecondLocator(interval=60))\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
    "plt.xticks(rotation=90)\n",
    "# plt.gcf().autofmt_xdate()\n",
    "\n",
    "\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Value') \n",
    "plt.title('SVM Model Prediction')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a85959d",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e52ffb0",
   "metadata": {},
   "source": [
    "<h1> using rolling window to calculate mean of predicted svm in 20s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70fca36",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_file['svm_predicted_rolling_mean'] = validation_file['svm_predicted'].rolling(window = 20).mean().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53982b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_file['svm_predicted_after_rolling_mean'] = 0\n",
    "\n",
    "validation_file.loc[validation_file['svm_predicted_rolling_mean'] > 0.6,['svm_predicted_after_rolling_mean']] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991b2c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation_file['HoverOrNot'] = validation_file['HoverOrNot'] /10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744219cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy of Model after second processing:\",accuracy_score(validation_file['HoverOrNot'],validation_file['svm_predicted_after_rolling_mean']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b3ca18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "\n",
    "# validation_file['svm_predicted'] = validation_svm * 30\n",
    "# validation_file['svm_predicted_after_rolling_mean'] = validation_file['svm_predicted_after_rolling_mean']  / 20 * 30\n",
    "# validation_file['HoverOrNot'] = validation_file['HoverOrNot']  * 10\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "plt.plot('datetime','absoluteAltitude',\n",
    "         data = validation_file,\n",
    "         label = \"absoluteAltitude\")\n",
    "plt.plot('datetime','groundSpeed',\n",
    "         data = validation_file,\n",
    "         label = \"groundSpeed\")\n",
    "plt.plot('datetime','svm_predicted',\n",
    "         data = validation_file,\n",
    "         label = \"svm_predicted\", color=\"orange\")\n",
    "plt.plot('datetime','svm_predicted_after_rolling_mean',\n",
    "         data = validation_file,\n",
    "         label = \"svm_predicted_after_rolling_mean\", color=\"green\")\n",
    "plt.plot('datetime','HoverOrNot',\n",
    "         data = validation_file,\n",
    "         label = \"HoverOrNot\", color=\"r\")\n",
    "\n",
    "#Set format of the plot chart\n",
    "plt.gca().xaxis.set_major_locator(mdates.SecondLocator(interval=60))\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
    "plt.xticks(rotation=90)\n",
    "# plt.gcf().autofmt_xdate()\n",
    "\n",
    "\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Value') \n",
    "plt.title('SVM Model Prediction')\n",
    "plt.legend(loc=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4699f3b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
